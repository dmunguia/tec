---
title: "Capítulo 11. Programación concurrente"
author: "Diego Munguía Molina ^[Esta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.]"
date: "Julio, 2020"
institute: "Ingeniería en Computación, TEC"
geometry: margin=1in
header-includes:
    - \usepackage{setspace}
    - \usepackage{comment}
    - \providecommand{\subtitle}[1]{\usepackage{titling} \posttitle{\par\large#1\end{center}}}
    - \usepackage[spanish]{babel}
    - \usepackage[linesnumbered,ruled,vlined,spanish,onelanguage]{algorithm2e}
    - \usepackage{amssymb}
    - \SetKwInput{KwInput}{Entradas}
    - \SetKwInput{KwOutput}{Salidas}
    - \newcommand{\twodots}{\mathrel{{.}\,{.}}\nobreak}
    - \newcommand{\assign}{\leftarrow}
    - \DeclareMathOperator{\ordenar}{ordenar}
    - \DeclareMathOperator{\bits}{bits}
    - \DeclareMathOperator{\azar}{azar}
output:
  pdf_document:
    latex_engine: xelatex
---

Todos los algoritmos que hemos estudiado hasta este punto presuponen un flujo secuencial de ejecución; cada uno de estos algoritmos se ejecuta como una secuencia lineal de pasos.

Esto quiere decir que presuponemos que los pasos o instrucciones tienen un orden específico: hay una instrucción inicial que llamaremos $i_1$, y posterior a esta se ejecutará la siguiente instrucción en la lista $i_2$, y sucesivamente se ejecutarán las siguientes instrucciones en el orden lineal (o monotónico) hasta ejecutar la última instrucción $i_k$. La figura $\ref{fig:secuencial}$ ilustra este concepto.

![Algoritmo secuencial\label{fig:secuencial}](plots/alg_secuencial.png){ width=350px }

La decisión sobre la siguiente instrucción a ejecutar no siempre sigue necesariamente un orden monotónico. Ocasionalmente el flujo de ejecución puede caer en ciclos como el que observamos en la figura $\ref{fig:secuencial}$ entre las instrucciones $i_2$, $i_3$ e $i_4$. La instrucción $i_4$ decide cuál será la siguiente instrucción a ejecutar (sea $i_2$ o $i_5$) con base en alguna condición relacionada con el estado actual de la máquina.

Este flujo también puede decidir saltar hacia adelante en la ejecución, por ejemplo en el caso de la instrucción $i_5$, alguna condición puede cambiar la decisión sobre cuál será la siguiente instrucción a ejecutar, ya sea $i_6$ o $i_k$, siendo este último el caso ilustrado en la figura $\ref{fig:secuencial}$.

El flujo secuencial es entonces un flujo lógico, obedece a mecanismos de control basados en predicados que se verifican contra el estado del programa para decidir cuál será la siguiente instrucción a ejecutar en la secuencia. Reconocemos estos mecanismos de control en instrucciones comúnes como los condicionales `if...then...else` o `switch...case`, y en ciclos como `while`, `do...while`, o `for`.

Independientemente de que el flujo permita saltar hacia atrás o hacia adelante en la secuencia de instrucciones, es sin lugar a duda un flujo único, un solo **hilo** conductor de la lógica del algoritmo.

La programación concurrente se refiere al diseño e implementación de algoritmos que manejan múltiples hilos de control. La figura $\ref{fig:concurrente}$ ilustra un ejemplo de un algoritmo concurrente con tres hilos.

![Algoritmo concurrente\label{fig:concurrente}](plots/alg_concurrente.png){ width=450px }

Un algoritmo concurrente maneja múltiples hilos lógicos. En el caso de nuestro ejemplo, un hilo principal, que es el hilo que inicia la ejecución, y dos hilos $a$ y $b$ disparados desde el hilo principal a partir de las instrucciones `start a` y `start b`. Desde una perspectiva lógica podemos asumir que una vez que se dispara un hilo nuevo este estará en ejecución al mismo tiempo que los otros hilos del programa, es decir suponemos que los hilos son (al menos aparentemente) simultáneos.

De esta forma, cuando el hilo principal ejecuta la segunda instrucción, etiquetada como `start a`, se dispara un nuevo hilo con el código de $a$, e inmediatamente el hilo principal pasa a ejecutar la tercer instrucción (que también dispara un hilo).

Cada hilo continuará ejecutando sus instrucciones sin detenerse a esperar los resultados de la ejecución de instrucciones en los otros hilos. Esto se cumple siempre excepto para instrucciones especiales como la penúltima presentada en la figura $\ref{fig:concurrente}$ etiquetada como `join b`. Cuando se ejecuta esta instrucción, el hilo principal queda bloqueado hasta que el hilo $b$ finalice su ejecución. Puesto que no hay una instrucción `join a` en ninguno de los hilos, la ejecución del hilo $a$ se realizará de manera independiente de los otros dos hilos. En contraste, el hilo principal depende del hilo $b$.

![Paralelismo\label{fig:paralelismo}](plots/paralelismo.png){ width=450px }

Los algoritmos concurrentes pueden ser ejecutados en paralelo. Cuando un algoritmo se ejecuta en paralelo distintos hilos se asignan a distintos procesadores, cada procesador ejecuta la instrucciones de su correspondiente hilo de manera realmente simultánea. La figura $\ref{fig:paralelismo}$ (b) ilustra este caso; un algoritmo paralelizado podría potencialmente ejecutarse más rápido que un algoritmo secuencial pues tiene acceso a más recursos de procesamiento. Sin embargo, un mal diseño del algoritmo concurrente podría tener peor desempeño que uno secuencial.

Por otro lado, cuando un algoritmo concurrente se ejecuta en un único procesador sus hilos son tan solo aparentemente simultáneos, según se ilustra en la figura $\ref{fig:paralelismo}$ (a). Esta aparente simultaneidad se logra aprovechando los tiempos muertos del procesador. Cuando una instrucción requiere de acceso a un dispositivo de entrada/salida, la memoria o el sistema de archivos las señales deben recorrer una distancia física real que toma más tiempo que el acceso a la memoria de trabajo ubicada a lo interno del procesador. Este tiempo de espera puede ser aprovechado resolviendo otras instrucciones de otros hilos de ejecución.

![Intercalado de instrucciones\label{fig:intercalado}](plots/intercalado.png)

La figura $\ref{fig:intercalado}$ presenta una posible ejecución de nuestro algoritmo concurrente de ejemplo en un único procesador. En la figura podemos observar que el procesador va intercalando instrucciones tanto del hilo principal, como de los hilos $a$ y $b$, siguiendo el orden lógico de cada hilo y aprovechando los tiempos de espera que pueda generar alguna instrucción. La decisión de cuál instrucción ejecutar en un momento determinado puede ser responsabilidad del hardware, del sistema operativo o de alguna combinación de ambos.

Con base en esto, podemos determinar que cuando tenemos un único procesador, el uso de algoritmos concurrentes vale la pena cuando las tareas por resolver implican un uso intensivo de entrada/salida —ya sea a través del sistema de archivos, dispositivos periféricos, o la red por ejemplo—. Por ejemplo en aplicaciones relacionadas con bases de datos, interfaz de usuario o servicios web. Mientras que los algoritmos concurrentes intensivos en el uso de procesador, como por ejemplo las redes neuronales o la renderización de gráficos tridimensionales, son recomendables cuando hay disponibilidad de múltiples procesadores.

arquitecturas paralelas

ejemplo de test de primalidad concurrente

condiciones de carrera  y sincronización

modelo PRAM



## Ejercicios ##


## Referencias ##

Butcher P. (2014) Seven Concurrency Models in Seven Weeks. Pragmatic Bookshelf.
