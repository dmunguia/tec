---
title: "Capítulo 4. Análisis de casos"
author: "Diego Munguía Molina ^[Esta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.]"
date: "Marzo, 2019"
institute: "Ingeniería en Computación, TEC"
geometry: margin=1in
header-includes:
    - \usepackage{setspace}
    - \providecommand{\subtitle}[1]{\usepackage{titling} \posttitle{\par\large#1\end{center}}}
    - \usepackage[spanish]{babel}
    - \usepackage[linesnumbered,ruled,vlined,spanish,onelanguage]{algorithm2e}
    - \usepackage{amssymb}
    - \SetKwInput{KwInput}{Entradas}
    - \SetKwInput{KwOutput}{Salidas}
    - \newcommand{\twodots}{\mathrel{{.}\,{.}}\nobreak}
    - \newcommand{\assign}{\leftarrow}
    - \DeclareMathOperator{\inter}{inter}
output:
  pdf_document:
    latex_engine: xelatex
---

Retomando el problema de ordenamiento, analicemos ahora la complejidad temporal del algoritmo de ordenamiento por inserción (_Insertion Sort_).

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Una secuencia de $n$ enteros $A$ tal que $n \ge 1$ y $\forall i \in [0 \twodots (n-1)[$ se cumple que $a_i \le a_{i+1} \lor a_i \ge a_{i+1}$}
    \KwOutput{Una permutación de $A$, $A^\prime = [a_1, a_2, \dots, a_n]$ tal que $a_1 \le a_2 \le \dots \le a_n$}
  
    \BlankLine
    \caption{Ordenamiento por inserción}
    \SetAlgoVlined
    
    \For{$i \in [0 \twodots n[$} {
        $j \assign i$ \;
        \While{$j > 0 \land A[j] < A[j-1]$} {
            $tmp \assign A[j]$ \;
            $A[j] \assign A[j-1]$ \;
            $A[j-1] \assign tmp$ \;

            $j \assign j-1$ \;
        }
    }

\end{algorithm}

En este algoritmo observamos que la fuente de complejidad temporal surge de los ciclos anidados en las líneas 1 y 3.

Debido a la línea 2, donde definimos el índice $j$ del ciclo interior con base en el índice $i$ del ciclo exterior, establecemos que ambos ciclos son dependientes entre si y por tanto deben ser analizados en conjunto.

Observamos que el ciclo exterior hace un recorrido completo de $n$ iteraciones, desde $0$ hasta $(n-1)$. Sin embargo, cuando observamos el ciclo interior podemos notar que su condición de parada depende del contenido de la secuencia $A$, pues el segundo término de la conjunción lógica establece que $A[j] < A[j-1]$ se debe cumplir para poder seguir iterando.

Este hecho complica el análisis, pues no podemos determinar cuántas veces repetirá el ciclo interior sin conocer de antemano cuál será el contenido de la secuencia $A$ que será ordenada.

Cuando la complejidad de un algoritmo depende de los datos con los que será ejecutado tenemos que hacer un análisis de casos. Este análisis requiere establecer casos, entendidos como las posibles distintas configuraciones de los datos de entrada de un mismo tamaño que representen correspondiente la peor y mejor expectativas posibles sobre la complejidad en cuestión. Además del mejor y peor caso posible, también podemos incluir el caso promedio en nuestro análisis.

## Peor caso ##

El peor caso para un algoritmo está determinado por la configuración de entradas que produzca el máximo consumo del recurso analizado.

Volviendo a nuestro ejemplo de ordenamiento por inserción, el peor caso está determinado por la permutación de $A$ de tamaño $n$ que obligue al algoritmo a ejecutar el número máximo de iteraciones del ciclo interior posibles. Esta permutación puede ser cualquier secuencia ordenada descendentemente.

Tomemos por ejemplo:

$$
A = [9,5,3,1,0]
$$

Cuando $j=1$ tendremos que el $5$ será menor que el $9$ y por tanto deberán ser intercambiados.

$$
A = [5,9,3,1,0]
$$

En la siguiente iteración con $j=2$ el $3$ será menor que el $5$ y $9$, y por tanto serán necesarios dos intercambios.

$$
A = [3,5,9,1,0]
$$

Claramente con $j=3$ y $j=4$ se repite el patrón pues el $1$ será menor que todos los números a su izquierda, y lo mismo sucederá con el $0$.

Cuando la secuencia está ordenada descendentemente, el término $A[j] < A[j-1]$ en la condición de parada del ciclo interior siempre será verdadero. De esta forma el ciclo pasa a ser dirigido por el primer término de la conjunción $j > 0$.

Esto hace que el ciclo interior repita $i$ veces desde $j=i$ hasta $j=1$.

Podemos entonces formular la función de complejidad temporal $T_p$ para el peor caso

$$
\begin{aligned}
T_p(n) = \sum_{i=1}^{n} \sum_{j=1}^{i} 1 \\
 = \sum_{i=1}^{n} i \\
 = \frac{n(n+1)}{2} \\
 \therefore T_p(n) = \mathcal{O}(n^2)
\end{aligned}
$$

## Mejor caso ##

El mejor caso para un algoritmo está determinado por la configuración de entradas que produzca el mínimo consumo del recurso analizado.

En el caso del algoritmo de ordenamiento por inserción, el mejor caso está dado por la permutación de $A$ de tamaño $n$ que ya se encuentra ordenada ascendentemente. Por ejemplo

$$
A = [0,1,3,5,9]
$$

En este caso, para cualquier $j \in [1 \twodots 4]$ los números a la izquierda de $j$ siempre serán menores que $A[j]$. Provocando de esta forma que el término $A[j] < A[j-1]$ en la condición de parada del ciclo interior siempre sea falso; por lo tanto, para cualquier $i$, el ciclo interior nunca se ejecutará.

Podemos formular entonces la función de complejidad temporal para el mejor caso $T_m$ como

$$
\begin{aligned}
T_m(n) = \sum_{i=1}^{n} 1 \\
 = n \\
 \therefore T_m(n) = \mathcal{O}(n)
\end{aligned}
$$

## Caso promedio ##

Finalmente, el caso promedio para un algoritmo está determinado por el consumo promedio del recurso analizado con base en todas las posibles configuraciones de entrada.

Observar todas las posibles configuraciones de las entradas es una tarea en muchos casos inmanejable y en otros casos simplemente imposible. Por esta razón, podemos utilizar teoría de probabilidades para estimar la complejidad del caso promedio.

Para el caso promedio del ordenamiento por inserción, primero debemos tomar en cuenta que existen $n!$ posibles permutaciones para una secuencia $A$ de tamaño $n$. La estimación parte del supuesto de que cada una de estas permutaciones es equiprobable, por tanto podemoms trabajar con las permutaciones como una variable aleatoria.

Supongamos que $A$ contiene los números naturales en el rango $[1 \twodots n]$ en un orden no determinado, es decir $A$ es una permutación de $\{1,2,\dots,n\}$.

Sea $(p, q)$ un par tal que $p, q \in A$, $1 \le p < q \le n$. Llamaremos a $(p, q)$ un _intercambio_ en $A$ si se cumple que el índice de $q$ es menor que el índice de $p$ en $A$, es decir $q$ aparece antes que $p$ en la secuencia $A$.

Por ejemplo para

$$
A = [2,5,3,4,1]
$$

identificamos los siguientes intercambios

$$
\{(1, 2), (3, 5), (4, 5), (1, 5), (1, 3), (1, 4)\}
$$

Definimos ahora la variable aleatoria $I_{p, q}$ de la siguiente manera

\begin{equation}
I_{p, q} = \begin{cases}
    1, & \text{si $(p, q)$ es un intercambio en $A$}.\\
    0, & \text{si $(p, q)$ no es un intercambio en $A$}.
  \end{cases}
\end{equation}

Con base en esta variable, definimos ahora la función $\inter(p)$

\begin{equation}
    \inter(p) = \sum_{q=p+1}^{n} I_{p, q}
\end{equation}

como el número total de intercambios de la forma $(p, q)$ en la permutación $A$ para un $p$ dado.

Tomemos ahora un $p = A[k]$ cualquiera. ¿Cuántos intercambios se realizarán cuando se compare con el resto de elementos a su izquierda?

Si $k=0$ entonces no se realiza ningún intercambio puesto que estamos al principio de la secuencia y ya no hay más elementos a su izquierda.

Cuando $k > 0$, de acuerdo con el funcionamimento del algoritmo, todos los elementos a la izquierda de $k$ ya se encuentran ordenados

## Referencias ##

